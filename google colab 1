{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZY/ETaNCgDZvbtm3TA2K3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallejahnavireddy14/google-colab-data/blob/main/google%20colab%201\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7QmWsaMc5GR",
        "outputId": "dad34f88-e0ae-4ba7-dad0-cc819178be32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 2278.9392 - val_loss: 526.7429\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 251.2300 - val_loss: 61.5210\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 20.7391 - val_loss: 5.7818\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 3.3743 - val_loss: 1.9649\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.4181 - val_loss: 1.0001\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.7472 - val_loss: 0.5312\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.2914\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.2251 - val_loss: 0.1688\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.1367 - val_loss: 0.1121\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0927 - val_loss: 0.0793\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0694 - val_loss: 0.0615\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0486\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0385\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0343 - val_loss: 0.0303\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0266 - val_loss: 0.0231\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0202 - val_loss: 0.0173\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0152 - val_loss: 0.0129\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0110 - val_loss: 0.0092\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0068\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0057 - val_loss: 0.0049\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0042 - val_loss: 0.0036\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0028\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0019\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0018\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0018\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0016\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0016\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.0022\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0016 - val_loss: 0.0016\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0017 - val_loss: 0.0018\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0016 - val_loss: 0.0014\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0018 - val_loss: 0.0015\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.0017 - val_loss: 0.0014\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0015\n",
            "Test Loss: 0.0015035924734547734\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Predicted Sum: 67.99943542480469\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP9S3hNWfWdh",
        "outputId": "8e14b43a-2f07-450a-eaa3-ead0f841fc18"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 1s 4ms/step - loss: 12324.3174 - val_loss: 11089.0684\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 11414.9922 - val_loss: 9702.8135\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 7181.0601 - val_loss: 3324.0059\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1215.1804 - val_loss: 78.3775\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 16.0454 - val_loss: 0.9179\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.9273\n",
            "Test Loss: 0.92728590965271\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Predicted Sum: 68.46467590332031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjbU_IcJfxqX",
        "outputId": "3fadae50-2814-496f-819f-6e14c2383146"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 2s 5ms/step - loss: 4725.0024 - val_loss: 347.7426\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 90.1681 - val_loss: 10.1621\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 5.0237 - val_loss: 4.1946\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.6728 - val_loss: 3.7716\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 3.3185 - val_loss: 3.3837\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 2.9855 - val_loss: 3.0226\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 2.6626 - val_loss: 2.6761\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 2.3584 - val_loss: 2.3508\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 2.0896 - val_loss: 2.0530\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 1.8499 - val_loss: 1.8037\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.6842\n",
            "Test Loss: 1.6841741800308228\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "Predicted Sum: 68.0900650024414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvNAP4XjgShK",
        "outputId": "5e3ffc69-d437-4471-8c25-1e1250c24f70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 11972.3691 - val_loss: 8562.1318\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 5520.7441 - val_loss: 2731.0420\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1182.2886 - val_loss: 166.7411\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 33.7705 - val_loss: 6.0060\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 3.1661 - val_loss: 1.5686\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.1825 - val_loss: 0.9433\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.8265 - val_loss: 0.7394\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.6734 - val_loss: 0.6229\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.5723 - val_loss: 0.5382\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5008 - val_loss: 0.4751\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.4450 - val_loss: 0.4249\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.4004 - val_loss: 0.3841\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3639 - val_loss: 0.3514\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3339 - val_loss: 0.3244\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3091 - val_loss: 0.3031\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.3094\n",
            "Test Loss: 0.3093918263912201\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "Predicted Sum: 68.3821792602539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=22, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq6b3NHUgb4g",
        "outputId": "f2147e4c-f466-4e26-bfea-e66d38a14798"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "291/291 [==============================] - 2s 3ms/step - loss: 67.8882 - val_loss: 0.9314\n",
            "Epoch 2/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.5176 - val_loss: 0.2726\n",
            "Epoch 3/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.1820 - val_loss: 0.1212\n",
            "Epoch 4/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0913 - val_loss: 0.0669\n",
            "Epoch 5/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0511 - val_loss: 0.0383\n",
            "Epoch 6/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0325 - val_loss: 0.0257\n",
            "Epoch 7/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0233 - val_loss: 0.0227\n",
            "Epoch 8/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0175 - val_loss: 0.0141\n",
            "Epoch 9/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0130 - val_loss: 0.0107\n",
            "Epoch 10/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0097 - val_loss: 0.0081\n",
            "Epoch 11/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0073 - val_loss: 0.0060\n",
            "Epoch 12/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0052 - val_loss: 0.0042\n",
            "Epoch 13/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0038\n",
            "Epoch 14/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 15/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 16/20\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0012 - val_loss: 8.6797e-04\n",
            "Epoch 17/20\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 7.5847e-04 - val_loss: 7.0974e-04\n",
            "Epoch 18/20\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 4.8769e-04 - val_loss: 5.8203e-04\n",
            "Epoch 19/20\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 3.0243e-04 - val_loss: 2.3236e-04\n",
            "Epoch 20/20\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 1.9664e-04 - val_loss: 1.3028e-04\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 9.9412e-05\n",
            "Test Loss: 9.941182361217216e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f663410eb00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "Predicted Sum: 68.0021743774414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=32, batch_size=60, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyeZ-RnEgo73",
        "outputId": "fc221403-89ff-4d82-ec33-dc2015c04178"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "107/107 [==============================] - 1s 4ms/step - loss: 12600.8633 - val_loss: 8217.8203\n",
            "Epoch 2/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 5153.2119 - val_loss: 2583.7407\n",
            "Epoch 3/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 1209.3063 - val_loss: 391.1134\n",
            "Epoch 4/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 229.5707 - val_loss: 156.1432\n",
            "Epoch 5/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 121.7319 - val_loss: 97.8428\n",
            "Epoch 6/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 75.2426 - val_loss: 59.8114\n",
            "Epoch 7/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 46.2805 - val_loss: 37.3055\n",
            "Epoch 8/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 29.8038 - val_loss: 25.0323\n",
            "Epoch 9/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 20.7908 - val_loss: 18.2326\n",
            "Epoch 10/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 15.6304 - val_loss: 14.1694\n",
            "Epoch 11/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 12.3687 - val_loss: 11.3821\n",
            "Epoch 12/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 10.0317 - val_loss: 9.3270\n",
            "Epoch 13/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 8.2206 - val_loss: 7.6640\n",
            "Epoch 14/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 6.7538 - val_loss: 6.3034\n",
            "Epoch 15/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 5.5337 - val_loss: 5.1627\n",
            "Epoch 16/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 4.5109 - val_loss: 4.1967\n",
            "Epoch 17/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 3.6428 - val_loss: 3.3796\n",
            "Epoch 18/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 2.9190 - val_loss: 2.7098\n",
            "Epoch 19/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 2.3181 - val_loss: 2.1512\n",
            "Epoch 20/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.8322 - val_loss: 1.6994\n",
            "Epoch 21/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 1.4443 - val_loss: 1.3486\n",
            "Epoch 22/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 1.1479 - val_loss: 1.0718\n",
            "Epoch 23/32\n",
            "107/107 [==============================] - 0s 2ms/step - loss: 0.9248 - val_loss: 0.8716\n",
            "Epoch 24/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.7644 - val_loss: 0.7302\n",
            "Epoch 25/32\n",
            "107/107 [==============================] - 0s 3ms/step - loss: 0.6523 - val_loss: 0.6325\n",
            "Epoch 26/32\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.5747 - val_loss: 0.5627\n",
            "Epoch 27/32\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.5207 - val_loss: 0.5143\n",
            "Epoch 28/32\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.4816 - val_loss: 0.4773\n",
            "Epoch 29/32\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.4521 - val_loss: 0.4487\n",
            "Epoch 30/32\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.4274 - val_loss: 0.4256\n",
            "Epoch 31/32\n",
            "107/107 [==============================] - 0s 4ms/step - loss: 0.4059 - val_loss: 0.4031\n",
            "Epoch 32/32\n",
            "107/107 [==============================] - 1s 5ms/step - loss: 0.3865 - val_loss: 0.3841\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.3873\n",
            "Test Loss: 0.38726159930229187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6635f108b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n",
            "Predicted Sum: 68.48898315429688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=34, batch_size=64, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcA0xv2VhWYC",
        "outputId": "92b0b584-4612-439c-8b2c-83bdd5bc7a40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "100/100 [==============================] - 2s 7ms/step - loss: 10124.7461 - val_loss: 7141.9126\n",
            "Epoch 2/34\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 2980.6685 - val_loss: 446.4298\n",
            "Epoch 3/34\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 121.7963 - val_loss: 28.5918\n",
            "Epoch 4/34\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 16.7437 - val_loss: 10.1968\n",
            "Epoch 5/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 8.9019 - val_loss: 6.8467\n",
            "Epoch 6/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 6.2735 - val_loss: 4.8501\n",
            "Epoch 7/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 4.5069 - val_loss: 3.5537\n",
            "Epoch 8/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 3.3658 - val_loss: 2.7193\n",
            "Epoch 9/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 2.6199 - val_loss: 2.1624\n",
            "Epoch 10/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 2.1331 - val_loss: 1.7747\n",
            "Epoch 11/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.7931 - val_loss: 1.4996\n",
            "Epoch 12/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 1.5418 - val_loss: 1.3028\n",
            "Epoch 13/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.3470 - val_loss: 1.1425\n",
            "Epoch 14/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.1972 - val_loss: 1.0251\n",
            "Epoch 15/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 1.0815 - val_loss: 0.9310\n",
            "Epoch 16/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.9856 - val_loss: 0.8556\n",
            "Epoch 17/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.9041 - val_loss: 0.7930\n",
            "Epoch 18/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.8322 - val_loss: 0.7387\n",
            "Epoch 19/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7729 - val_loss: 0.6920\n",
            "Epoch 20/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.7212 - val_loss: 0.6432\n",
            "Epoch 21/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6712 - val_loss: 0.5986\n",
            "Epoch 22/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.6274 - val_loss: 0.5625\n",
            "Epoch 23/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.5858 - val_loss: 0.5287\n",
            "Epoch 24/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5471 - val_loss: 0.5013\n",
            "Epoch 25/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5126 - val_loss: 0.4679\n",
            "Epoch 26/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4781 - val_loss: 0.4431\n",
            "Epoch 27/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4469 - val_loss: 0.4160\n",
            "Epoch 28/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.3915\n",
            "Epoch 29/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3942 - val_loss: 0.3671\n",
            "Epoch 30/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3711 - val_loss: 0.3513\n",
            "Epoch 31/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3496 - val_loss: 0.3292\n",
            "Epoch 32/34\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.3126\n",
            "Epoch 33/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.2933\n",
            "Epoch 34/34\n",
            "100/100 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.2757\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.2746\n",
            "Test Loss: 0.2746451199054718\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Predicted Sum: 68.75523376464844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=18, batch_size=57, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_9ZeOGFhjqM",
        "outputId": "c0432caa-718b-42ee-b7b6-064d3dd5b79f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 7468.1768 - val_loss: 3505.5835\n",
            "Epoch 2/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1049.8998 - val_loss: 20.3892\n",
            "Epoch 3/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 7.7778 - val_loss: 5.1553\n",
            "Epoch 4/18\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 3.6064 - val_loss: 2.8438\n",
            "Epoch 5/18\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 2.1752 - val_loss: 1.9109\n",
            "Epoch 6/18\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.6343 - val_loss: 1.5558\n",
            "Epoch 7/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.4142 - val_loss: 1.3812\n",
            "Epoch 8/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.2827 - val_loss: 1.2577\n",
            "Epoch 9/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 1.1731 - val_loss: 1.1416\n",
            "Epoch 10/18\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0678 - val_loss: 1.0382\n",
            "Epoch 11/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.9673 - val_loss: 0.9353\n",
            "Epoch 12/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.8730 - val_loss: 0.8465\n",
            "Epoch 13/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.7847 - val_loss: 0.7517\n",
            "Epoch 14/18\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 0.7015 - val_loss: 0.6672\n",
            "Epoch 15/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.6261 - val_loss: 0.5918\n",
            "Epoch 16/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 0.5244\n",
            "Epoch 17/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4928 - val_loss: 0.4620\n",
            "Epoch 18/18\n",
            "113/113 [==============================] - 0s 2ms/step - loss: 0.4366 - val_loss: 0.4092\n",
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4180\n",
            "Test Loss: 0.4179839789867401\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "Predicted Sum: 68.073486328125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "def generate_data(num_samples):\n",
        "    x1 = np.random.randint(0, 100, size=num_samples)\n",
        "    x2 = np.random.randint(0, 100, size=num_samples)\n",
        "    y = x1 + x2\n",
        "    return np.vstack((x1, x2)).T, y\n",
        "num_samples = 10000\n",
        "X, y = generate_data(num_samples)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=2, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=8, batch_size=50, validation_split=0.2)\n",
        "loss = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {loss}')\n",
        "sample_input = np.array([[23, 45]])\n",
        "predicted_sum = model.predict(sample_input)\n",
        "print(f'Predicted Sum: {predicted_sum[0][0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk1t6NvXg2wt",
        "outputId": "388222c6-585a-4019-b95c-bce984768631"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "128/128 [==============================] - 1s 4ms/step - loss: 10176.8848 - val_loss: 4797.6543\n",
            "Epoch 2/8\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 1768.2010 - val_loss: 304.1176\n",
            "Epoch 3/8\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 119.4093 - val_loss: 37.4322\n",
            "Epoch 4/8\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 23.3106 - val_loss: 18.5256\n",
            "Epoch 5/8\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 15.9111 - val_loss: 14.1999\n",
            "Epoch 6/8\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 12.6705 - val_loss: 11.3709\n",
            "Epoch 7/8\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 10.3037 - val_loss: 9.2644\n",
            "Epoch 8/8\n",
            "128/128 [==============================] - 0s 3ms/step - loss: 8.4579 - val_loss: 7.6387\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 8.5400\n",
            "Test Loss: 8.539966583251953\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "Predicted Sum: 67.04776763916016\n"
          ]
        }
      ]
    }
  ]
}